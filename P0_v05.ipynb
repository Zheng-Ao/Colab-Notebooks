{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "P0_v05.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "fKdAJ8l5F_yg",
        "C-W-OYm27Tj2",
        "-ofPd_sYUAty",
        "mgVZ4TC0Vda_",
        "F_Rn1K8pE3Z0",
        "wmFzeBC6qaHX",
        "DgQRy866G5JW",
        "m0KrE7E6LDCr",
        "HZwU5sBFyly0",
        "VNIQr9XuakxG",
        "6GSfZNi978Mu"
      ],
      "mount_file_id": "1Sqr4KjJKKhLBjnKrl_PrfHPUOMsYKDXX",
      "authorship_tag": "ABX9TyP9VdgK2j3aRgused7q01pE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zheng-Ao/Colab-Notebooks/blob/main/P0_v05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 全局设置"
      ],
      "metadata": {
        "id": "fKdAJ8l5F_yg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CR_-xEl5Emv2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb510eeb-5edb-48fb-a562-d6ddb1637179"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.12.0+cu113\n",
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "'''常用库导入'''\n",
        "import random\n",
        "random.seed(85)\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "raw_data_path = \"drive/MyDrive/P0/T10K.csv\"\n",
        "# 测试谷歌云端硬盘是否成功加载:\n",
        "# pd.read_csv(raw_data_path)\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "import torch\n",
        "print(torch.__version__)                                                        # 用于确定PyG的安装\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, Subset, ConcatDataset, DataLoader\n",
        "from torch.nn import functional as F\n",
        "\n",
        "# 检查GPU:\n",
        "# !nvidia-smi\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "'''特殊库安装(魔法函数要放在Cell的最开始)'''\n",
        "# 我不想输出安装信息，虽然%%capture不是用来干这个的，但它能达到我想要的效果\n",
        "!pip install transformers\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-1.12.0+cu113.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-1.12.0+cu113.html\n",
        "!pip install torch-geometric"
      ],
      "metadata": {
        "id": "q_Zxt-SIFo9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 数据探索，预处理，特征工程"
      ],
      "metadata": {
        "id": "C-W-OYm27Tj2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 原始数据转换为分析数据"
      ],
      "metadata": {
        "id": "UKYQ1QPPWJ_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data = pd.read_csv(raw_data_path, index_col=\"Unnamed: 0\")\n",
        "\n",
        "# 将3个字符串变成数值\n",
        "for str in [\"inventors\",\"assignees\",\"IPCs\"]:\n",
        "    for i in range(len(raw_data[str])):\n",
        "        if str == \"assignees\":\n",
        "            if raw_data[str].values[i] == \"[{'assignee_sequence': None, 'assignee_key_id': None}]\":\n",
        "                raw_data[str].values[i] = 0\n",
        "                continue\n",
        "        raw_data[str].values[i] = len(eval(raw_data[str].values[i]))\n",
        "\n",
        "for str in [\"inventors\",\"assignees\",\"IPCs\"]:\n",
        "    raw_data[str] = raw_data[str].astype(int)\n",
        "\n",
        "# raw_data.info()\n",
        "# raw_data.describe()"
      ],
      "metadata": {
        "id": "cpDvnTztV_VQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 数据清洗"
      ],
      "metadata": {
        "id": "-ofPd_sYUAty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''本次清洗原则：低被引，皆可删\n",
        "注意，清洗之后要重排id列，这是建图的必须！\n",
        "默认的索引也要重新改！否则无法正常的进行索引操作！比如原来index=2800的被删掉了，那么df.at[2800,\"someattr\"]就会报错！！！\n",
        "'''\n",
        "\n",
        "# raw_data.info()\n",
        "# 发现\"patent_abstract\"一列有缺失值，定位看看:\n",
        "raw_data[raw_data.isnull().values == True]\n",
        "# 发现是无关紧要的负样本，直接将它们删掉(10000->9993):\n",
        "raw_data.dropna(inplace = True)\n",
        "raw_data.reset_index(drop=True, inplace=True)\n",
        "# raw_data.info()\n",
        "# raw_data.describe()\n",
        "# 发现后向引用数的min为0，存在没有后向引用的专利吗？定位看看:\n",
        "# raw_data[raw_data[\"patent_num_us_patent_citations\"].values == 0]\n",
        "# 这些专利并非后向引用为0，而是引用了外国的专利，而非美国的专利。\n",
        "# raw_data[raw_data[\"patent_num_us_patent_citations\"].values == 1]\n",
        "# 这些专利还是有一定被引数的，因此保留下来\n",
        "num_patents = len(raw_data)\n",
        "raw_data.insert(0, 'index', range(num_patents), allow_duplicates=False)\n",
        "\n",
        "print(f\"最终有{num_patents}个专利\")"
      ],
      "metadata": {
        "id": "ON6lV9St7ZWx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "911ec1c7-23ff-4e0f-ff18-d8a8d58e9fe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "最终有9993个专利\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data"
      ],
      "metadata": {
        "id": "i69vMzfKkNX0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 991
        },
        "outputId": "aa324418-8fb3-4b94-a1b6-33f85118e6af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      index patent_number patent_date  patent_num_cited_by_us_patents  \\\n",
              "0         0       3930276  1976-01-06                               4   \n",
              "1         1       3930279  1976-01-06                               5   \n",
              "2         2       3930323  1976-01-06                              17   \n",
              "3         3       3930526  1976-01-06                              14   \n",
              "4         4       3930527  1976-01-06                              19   \n",
              "...     ...           ...         ...                             ...   \n",
              "9988   9988       4358129  1982-11-09                               1   \n",
              "9989   9989       4358133  1982-11-09                              32   \n",
              "9990   9990       4358135  1982-11-09                              22   \n",
              "9991   9991       4358136  1982-11-09                              32   \n",
              "9992   9992       4358148  1982-11-09                               4   \n",
              "\n",
              "                                           patent_title  \\\n",
              "0     Wheel spinning and vehicle conveying apparatus...   \n",
              "1     Rubber windshield wiper blades having increase...   \n",
              "2     Chain tensioning mechanism for scraper elevato...   \n",
              "3                   Pneumatic tire and wheel assemblies   \n",
              "4                               Tire and wheel assembly   \n",
              "...                                                 ...   \n",
              "9988  Tractor with a built-on underframe for a tilli...   \n",
              "9989                           Adjustable width trailer   \n",
              "9990   Connector for igniting circuit of priming device   \n",
              "9991  Energy absorbing device for use with vehicular...   \n",
              "9992                               Damped railway wheel   \n",
              "\n",
              "                                        patent_abstract  patent_num_claims  \\\n",
              "0     An automobile conveyor for use in conjunction ...                 12   \n",
              "1     A rubber windshield wiper blade is clamped to ...                  2   \n",
              "2     A tensioning mechanism for the chain of a scra...                  2   \n",
              "3     A pneumatic tire and wheel assembly comprises ...                 21   \n",
              "4     A wheel having a pair of spaced-apart seats fo...                  8   \n",
              "...                                                 ...                ...   \n",
              "9988  The back part of the underframe is fastened to...                  2   \n",
              "9989  A trailer frame having fixed wheel track is pr...                  6   \n",
              "9990  A connector provided in an igniting circuit fo...                  9   \n",
              "9991  An energy absorbing device for use with a vehi...                  7   \n",
              "9992  A vibration damping assembly for a wheel or th...                  8   \n",
              "\n",
              "      patent_num_us_patent_citations  inventors  assignees  IPCs  \\\n",
              "0                                  2          1          1     1   \n",
              "1                                  3          1          0     1   \n",
              "2                                  4          2          1     2   \n",
              "3                                  7          1          1     1   \n",
              "4                                 13          1          1     4   \n",
              "...                              ...        ...        ...   ...   \n",
              "9988                               4          1          0     1   \n",
              "9989                               6          1          0     1   \n",
              "9990                               7          4          1     2   \n",
              "9991                               7          4          1     1   \n",
              "9992                              10          1          1     4   \n",
              "\n",
              "                                          cited_patents  \n",
              "0     [{'cited_patent_number': '3037223', 'cited_pat...  \n",
              "1     [{'cited_patent_number': '2140453', 'cited_pat...  \n",
              "2     [{'cited_patent_number': '372157', 'cited_pate...  \n",
              "3     [{'cited_patent_number': '1359461', 'cited_pat...  \n",
              "4     [{'cited_patent_number': '1921772', 'cited_pat...  \n",
              "...                                                 ...  \n",
              "9988  [{'cited_patent_number': '2707643', 'cited_pat...  \n",
              "9989  [{'cited_patent_number': '3239274', 'cited_pat...  \n",
              "9990  [{'cited_patent_number': '3509297', 'cited_pat...  \n",
              "9991  [{'cited_patent_number': '3547468', 'cited_pat...  \n",
              "9992  [{'cited_patent_number': '734417', 'cited_pate...  \n",
              "\n",
              "[9993 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-79bd7a59-5a1b-44cc-b14e-09df378b0840\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>patent_number</th>\n",
              "      <th>patent_date</th>\n",
              "      <th>patent_num_cited_by_us_patents</th>\n",
              "      <th>patent_title</th>\n",
              "      <th>patent_abstract</th>\n",
              "      <th>patent_num_claims</th>\n",
              "      <th>patent_num_us_patent_citations</th>\n",
              "      <th>inventors</th>\n",
              "      <th>assignees</th>\n",
              "      <th>IPCs</th>\n",
              "      <th>cited_patents</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3930276</td>\n",
              "      <td>1976-01-06</td>\n",
              "      <td>4</td>\n",
              "      <td>Wheel spinning and vehicle conveying apparatus...</td>\n",
              "      <td>An automobile conveyor for use in conjunction ...</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[{'cited_patent_number': '3037223', 'cited_pat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3930279</td>\n",
              "      <td>1976-01-06</td>\n",
              "      <td>5</td>\n",
              "      <td>Rubber windshield wiper blades having increase...</td>\n",
              "      <td>A rubber windshield wiper blade is clamped to ...</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[{'cited_patent_number': '2140453', 'cited_pat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3930323</td>\n",
              "      <td>1976-01-06</td>\n",
              "      <td>17</td>\n",
              "      <td>Chain tensioning mechanism for scraper elevato...</td>\n",
              "      <td>A tensioning mechanism for the chain of a scra...</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>[{'cited_patent_number': '372157', 'cited_pate...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3930526</td>\n",
              "      <td>1976-01-06</td>\n",
              "      <td>14</td>\n",
              "      <td>Pneumatic tire and wheel assemblies</td>\n",
              "      <td>A pneumatic tire and wheel assembly comprises ...</td>\n",
              "      <td>21</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[{'cited_patent_number': '1359461', 'cited_pat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>3930527</td>\n",
              "      <td>1976-01-06</td>\n",
              "      <td>19</td>\n",
              "      <td>Tire and wheel assembly</td>\n",
              "      <td>A wheel having a pair of spaced-apart seats fo...</td>\n",
              "      <td>8</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>[{'cited_patent_number': '1921772', 'cited_pat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9988</th>\n",
              "      <td>9988</td>\n",
              "      <td>4358129</td>\n",
              "      <td>1982-11-09</td>\n",
              "      <td>1</td>\n",
              "      <td>Tractor with a built-on underframe for a tilli...</td>\n",
              "      <td>The back part of the underframe is fastened to...</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[{'cited_patent_number': '2707643', 'cited_pat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9989</th>\n",
              "      <td>9989</td>\n",
              "      <td>4358133</td>\n",
              "      <td>1982-11-09</td>\n",
              "      <td>32</td>\n",
              "      <td>Adjustable width trailer</td>\n",
              "      <td>A trailer frame having fixed wheel track is pr...</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[{'cited_patent_number': '3239274', 'cited_pat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9990</th>\n",
              "      <td>9990</td>\n",
              "      <td>4358135</td>\n",
              "      <td>1982-11-09</td>\n",
              "      <td>22</td>\n",
              "      <td>Connector for igniting circuit of priming device</td>\n",
              "      <td>A connector provided in an igniting circuit fo...</td>\n",
              "      <td>9</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>[{'cited_patent_number': '3509297', 'cited_pat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9991</th>\n",
              "      <td>9991</td>\n",
              "      <td>4358136</td>\n",
              "      <td>1982-11-09</td>\n",
              "      <td>32</td>\n",
              "      <td>Energy absorbing device for use with vehicular...</td>\n",
              "      <td>An energy absorbing device for use with a vehi...</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[{'cited_patent_number': '3547468', 'cited_pat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9992</th>\n",
              "      <td>9992</td>\n",
              "      <td>4358148</td>\n",
              "      <td>1982-11-09</td>\n",
              "      <td>4</td>\n",
              "      <td>Damped railway wheel</td>\n",
              "      <td>A vibration damping assembly for a wheel or th...</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>[{'cited_patent_number': '734417', 'cited_pate...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9993 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-79bd7a59-5a1b-44cc-b14e-09df378b0840')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-79bd7a59-5a1b-44cc-b14e-09df378b0840 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-79bd7a59-5a1b-44cc-b14e-09df378b0840');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 看一看正负样本分别长什么样"
      ],
      "metadata": {
        "id": "mgVZ4TC0Vda_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# raw_data.nlargest(10,\"patent_num_cited_by_us_patents\")\n",
        "pos_some_data = raw_data[raw_data[\"patent_num_cited_by_us_patents\"]>40]\n",
        "pos_some_data.info()\n",
        "pos_some_data.describe()"
      ],
      "metadata": {
        "id": "b_MsEyGb9tLo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "outputId": "2e32899f-3640-4d1e-f6c4-2ed963b0ebae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 534 entries, 9 to 9986\n",
            "Data columns (total 12 columns):\n",
            " #   Column                          Non-Null Count  Dtype \n",
            "---  ------                          --------------  ----- \n",
            " 0   index                           534 non-null    int64 \n",
            " 1   patent_number                   534 non-null    object\n",
            " 2   patent_date                     534 non-null    object\n",
            " 3   patent_num_cited_by_us_patents  534 non-null    int64 \n",
            " 4   patent_title                    534 non-null    object\n",
            " 5   patent_abstract                 534 non-null    object\n",
            " 6   patent_num_claims               534 non-null    int64 \n",
            " 7   patent_num_us_patent_citations  534 non-null    int64 \n",
            " 8   inventors                       534 non-null    int64 \n",
            " 9   assignees                       534 non-null    int64 \n",
            " 10  IPCs                            534 non-null    int64 \n",
            " 11  cited_patents                   534 non-null    object\n",
            "dtypes: int64(7), object(5)\n",
            "memory usage: 54.2+ KB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             index  patent_num_cited_by_us_patents  patent_num_claims  \\\n",
              "count   534.000000                      534.000000         534.000000   \n",
              "mean   5373.569288                       63.183521          11.292135   \n",
              "std    2930.359191                       32.245424          11.342066   \n",
              "min       9.000000                       41.000000           1.000000   \n",
              "25%    3042.000000                       46.000000           5.000000   \n",
              "50%    5578.500000                       52.000000           8.000000   \n",
              "75%    7960.000000                       68.750000          14.000000   \n",
              "max    9979.000000                      284.000000         123.000000   \n",
              "\n",
              "       patent_num_us_patent_citations   inventors   assignees        IPCs  \n",
              "count                      534.000000  534.000000  534.000000  534.000000  \n",
              "mean                         6.790262    1.614232    0.662921    1.485019  \n",
              "std                          4.091016    0.961288    0.514929    0.800305  \n",
              "min                          0.000000    1.000000    0.000000    1.000000  \n",
              "25%                          4.000000    1.000000    0.000000    1.000000  \n",
              "50%                          6.000000    1.000000    1.000000    1.000000  \n",
              "75%                          9.000000    2.000000    1.000000    2.000000  \n",
              "max                         35.000000    6.000000    3.000000    5.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-787700b3-ee2b-4219-ad7b-fdc59f0f553a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>patent_num_cited_by_us_patents</th>\n",
              "      <th>patent_num_claims</th>\n",
              "      <th>patent_num_us_patent_citations</th>\n",
              "      <th>inventors</th>\n",
              "      <th>assignees</th>\n",
              "      <th>IPCs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>534.000000</td>\n",
              "      <td>534.000000</td>\n",
              "      <td>534.000000</td>\n",
              "      <td>534.000000</td>\n",
              "      <td>534.000000</td>\n",
              "      <td>534.000000</td>\n",
              "      <td>534.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5373.569288</td>\n",
              "      <td>63.183521</td>\n",
              "      <td>11.292135</td>\n",
              "      <td>6.790262</td>\n",
              "      <td>1.614232</td>\n",
              "      <td>0.662921</td>\n",
              "      <td>1.485019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2930.359191</td>\n",
              "      <td>32.245424</td>\n",
              "      <td>11.342066</td>\n",
              "      <td>4.091016</td>\n",
              "      <td>0.961288</td>\n",
              "      <td>0.514929</td>\n",
              "      <td>0.800305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>9.000000</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3042.000000</td>\n",
              "      <td>46.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5578.500000</td>\n",
              "      <td>52.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>7960.000000</td>\n",
              "      <td>68.750000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>9979.000000</td>\n",
              "      <td>284.000000</td>\n",
              "      <td>123.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-787700b3-ee2b-4219-ad7b-fdc59f0f553a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-787700b3-ee2b-4219-ad7b-fdc59f0f553a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-787700b3-ee2b-4219-ad7b-fdc59f0f553a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**可以看到基本上没什么规律，除非能够很好地理解文本，否则很难自动地将它们挑出来。**"
      ],
      "metadata": {
        "id": "g3-M93QIaXeg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 将分析数据转换为输入特征"
      ],
      "metadata": {
        "id": "I4zDxm3sb00q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 数值特征归一化"
      ],
      "metadata": {
        "id": "hHq4fFKlgLVD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for str in [\"patent_num_claims\",\"patent_num_us_patent_citations\",\"inventors\",\"assignees\",\"IPCs\"]:\n",
        "    raw_data[str] = (raw_data[str] - raw_data[str].mean())/raw_data[str].std()"
      ],
      "metadata": {
        "id": "UjB4DHL1Wyb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# raw_data"
      ],
      "metadata": {
        "id": "S3BmMYvS9tJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 文本特征提取"
      ],
      "metadata": {
        "id": "_87Ekpruce4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''构建txt_vecs，作为Dataset的第二个数据来源'''\n",
        "from transformers import DistilBertTokenizer, DistilBertModel\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")      \n",
        "nlp_model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\").to(device)\n",
        "'''加载BERT这种大模型很耗时，因此在整个流程中应当让上面两行代码只执行一次。'''"
      ],
      "metadata": {
        "id": "Fc3zwgx_WRXm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "8b4dd179-6419-469e-c1b2-44f880b7ddcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'加载BERT这种大模型很耗时，因此在整个流程中应当让上面两行代码只执行一次。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''此循环较贵(num_patents/150 秒)，但无法避免'''\n",
        "for i in tqdm(range(num_patents)):\n",
        "    ttl = raw_data[\"patent_title\"].values[i]\n",
        "    abst = raw_data[\"patent_abstract\"].values[i]\n",
        "    txt_input = ttl + \" \" + abst\n",
        "    inputs = tokenizer(txt_input, return_tensors=\"pt\").to(device)\n",
        "    if len(inputs['input_ids'][0]) > 512:\n",
        "        outputs = nlp_model(input_ids = inputs['input_ids'][0, :510], attention_mask = inputs['attention_mask'][0, :510])\n",
        "    else:\n",
        "        outputs = nlp_model(**inputs)\n",
        "    last_hidden_states = outputs.last_hidden_state\n",
        "    cls_vec = last_hidden_states[:,0,:].clone().detach()\n",
        "    if i == 0:\n",
        "        txt_vecs = cls_vec\n",
        "    else:\n",
        "        txt_vecs = torch.cat([txt_vecs, cls_vec],dim=0)\n",
        "\n",
        "print(txt_vecs.shape)\n",
        "# should be [num_samples, embedding_dim]"
      ],
      "metadata": {
        "id": "TjwGItGlE5Eh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "6ea5ed5c-bf09-4c0a-9d50-e13d265a74df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 315/9993 [00:03<01:52, 86.19it/s] \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-98-d0459b84940c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m510\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m510\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (835) must match the existing size (510) at non-singleton dimension 0.  Target sizes: [835].  Tensor sizes: [510]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Mat = txt_vecs.cpu().numpy()\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# txt_pca = PCA(n_components=0.9, svd_solver = 'full')\n",
        "txt_pca = PCA(n_components = 5)"
      ],
      "metadata": {
        "id": "E_SqxF1chNgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 查看PCA的效果:\n",
        "txt_pca.fit(Mat)\n",
        "var = txt_pca.explained_variance_ratio_\n",
        "print(f\"PCA之后的维度：{len(var)}，PCA后的方差保留：{var.sum():.4f}\")"
      ],
      "metadata": {
        "id": "CaoLuPwphNVn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9986c82-3520-488f-e2db-2d82dc3e5027"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PCA之后的维度：5，PCA后的方差保留：0.4711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PCA\n",
        "Txt_Embedding_c = torch.tensor(txt_pca.fit_transform(Mat), dtype = torch.float32)\n",
        "print(Txt_Embedding_c.shape)\n",
        "# should be [10000, 5] here\n",
        "\n",
        "# without PCA\n",
        "Txt_Embedding = txt_vecs.clone()\n",
        "print(Txt_Embedding.shape, Txt_Embedding.dtype)"
      ],
      "metadata": {
        "id": "Wp1-4ZfciG91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "056056d4-bcf6-4807-aad2-4d74e0760db4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([9993, 5])\n",
            "torch.Size([9993, 768]) torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 图特征提取"
      ],
      "metadata": {
        "id": "WLuD8FMHdsIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# edge_index, edge_attr\n",
        "from datetime import datetime\n",
        "\n",
        "adj_ls = []\n",
        "edges = []\n",
        "\n",
        "for i in tqdm(range(num_patents)):\n",
        "    id = raw_data.values[i][0]\n",
        "    b_cits = eval(raw_data[\"cited_patents\"].values[i])\n",
        "    for b_cit in b_cits:\n",
        "        # 是否在专利数据库中\n",
        "        if b_cit[\"cited_patent_date\"]:\n",
        "            # 是否在本数据集中\n",
        "            if b_cit[\"cited_patent_number\"] in raw_data[\"patent_number\"].values:\n",
        "                # print(i)\n",
        "                cit_id = raw_data[raw_data[\"patent_number\"].values == b_cit[\"cited_patent_number\"]].values[0][0]\n",
        "                adj_ls.append([id, cit_id])\n",
        "                date = raw_data[\"patent_date\"].values[id]\n",
        "                cit_date = raw_data[\"patent_date\"].values[cit_id]\n",
        "                date1 = datetime.strptime(date, \"%Y-%m-%d\")\n",
        "                date2 = datetime.strptime(cit_date, \"%Y-%m-%d\")\n",
        "                dist = date1-date2\n",
        "                '''边的权重设置为365/间隔天数'''\n",
        "                dist = 365/dist.days\n",
        "                edges.append(dist)"
      ],
      "metadata": {
        "id": "JXWJMF7BPFT3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25f23950-7cf2-470e-f25f-7dd5c4128de7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9993/9993 [00:32<00:00, 305.09it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# adj_ls[0:10], edges[0:10]\n",
        "'''edges需要做归一化吗？'''"
      ],
      "metadata": {
        "id": "Jm2nU3jQPj3y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7d4d941f-0c35-4676-e12c-d0dd7562897b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'edges需要做归一化吗？'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1yfWAglKPj1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UTILS"
      ],
      "metadata": {
        "id": "F_Rn1K8pE3Z0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# target transform, 0:neg, 1:pos\n",
        "def LabelCorePa(ref, isd):\n",
        "    now = datetime.strptime(\"2022-01-01\", \"%Y-%m-%d\").year\n",
        "    years = now - datetime.strptime(isd, \"%Y-%m-%d\").year\n",
        "    score = ref/years       \n",
        "    label = int((score>0.5))\n",
        "    return label\n",
        "\n",
        "# Dataset\n",
        "class PatDataset(Dataset):\n",
        "    def __init__(self, raw_data, txt_vecs = None, transform = None, target_transform = LabelCorePa):\n",
        "        super().__init__()\n",
        "        self.raw_data = raw_data\n",
        "        self.txt_vecs = txt_vecs\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.raw_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Y          \n",
        "        ref = self.raw_data[\"patent_num_cited_by_us_patents\"].values[idx]\n",
        "        isd = self.raw_data.at[idx, \"patent_date\"]\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(ref, isd)\n",
        "            label = torch.tensor(label,dtype=torch.long)\n",
        "\n",
        "        # X\n",
        "        # INDEXs\n",
        "        num_claims = self.raw_data.at[idx, \"patent_num_claims\"]\n",
        "        num_b_cits = self.raw_data.at[idx, \"patent_num_us_patent_citations\"]\n",
        "        inventors = self.raw_data.at[idx, \"inventors\"]\n",
        "        # num_inventors = len(eval(inventors))\n",
        "        assignees = self.raw_data.at[idx, \"assignees\"]\n",
        "        # if assignees == \"[{'assignee_sequence': None, 'assignee_key_id': None}]\":\n",
        "        #     num_assignees = 0\n",
        "        # else:\n",
        "        #     num_assignees = len(eval(assignees))\n",
        "        IPCs = self.raw_data.at[idx, \"IPCs\"]\n",
        "        # num_ipcs = len(eval(IPCs))\n",
        "        indexs = torch.tensor([num_claims, num_b_cits, inventors, assignees, IPCs], dtype=torch.float32).to(device)\n",
        "        patent = indexs.clone()\n",
        "        # TXT\n",
        "        if self.txt_vecs != None:\n",
        "            txt_vec = self.txt_vecs[idx].clone()\n",
        "            txt_vec = txt_vec.to(device)\n",
        "            patent = torch.cat([indexs, txt_vec])\n",
        "        \n",
        "        return patent, label\n",
        "\n",
        "# Models\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super().__init__()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            # nn.BatchNorm1d(input_size),\n",
        "            # 不加BatchNorm效果更好，事实证明：不要去玩自己不会的东西\n",
        "            nn.Linear(input_size, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.5),\n",
        "            # nn.Linear(hidden_size, 128),\n",
        "            # nn.ReLU(),\n",
        "            # nn.Dropout(p=0.5),\n",
        "            # nn.Linear(128, 32),\n",
        "            # nn.ReLU(),\n",
        "            # nn.Dropout(p=0.5),\n",
        "            # nn.Linear(32, 8),\n",
        "            # nn.ReLU(),\n",
        "            # nn.Dropout(p=0.5),\n",
        "            # nn.Linear(8, output_size)\n",
        "            nn.Linear(hidden_size, output_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "class GNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(input_size, hidden_size)\n",
        "        self.conv2 = GCNConv(hidden_size, 2)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        logits = self.conv2(x, edge_index)                   # (num_nodes, 2)\n",
        "        return logits                  # (num_nodes, 2)\n",
        "\n",
        "\n",
        "\n",
        "# Train\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "\n",
        "        # batch: 第几个batch；X: 包含batch_size个feature vec.\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        output = model(X).to(device)\n",
        "        loss = loss_fn(output, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 20 == 0:                                                     # train_size/batch_size = 100, 每20个batch输出一次结果，共输出5次。\n",
        "            loss, current = loss.item(), batch * len(X)                         \n",
        "            # print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "# Test\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    model.eval()\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch, (X, y) in enumerate(dataloader):\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            output = model(X)\n",
        "            test_loss += loss_fn(output, y).item()\n",
        "            # correct += (output.argmax(1) == y).type(torch.float).sum().item()\n",
        "            \n",
        "            pred = output.argmax(1).cpu()\n",
        "            y = y.cpu()\n",
        "            if batch == 0:\n",
        "                Pred = pred\n",
        "                Y = y\n",
        "            else:\n",
        "                Pred = torch.cat((Pred, pred), dim = 0)\n",
        "                Y = torch.cat((Y, y), dim=0)\n",
        "\n",
        "    C_Mat = metrics.confusion_matrix(Y, Pred)\n",
        "    accuracy = metrics.accuracy_score(Y,Pred)\n",
        "    f1 = metrics.f1_score(Y, Pred)\n",
        "    recall = metrics.recall_score(Y, Pred)\n",
        "    precision = metrics.precision_score(Y, Pred)\n",
        "    print(C_Mat)\n",
        "    print(f\"{test_loss:.4f}\")\n",
        "    print(f\"acc:{accuracy:.4f}, f1:{f1:.4f}, recall:{recall:.4f}, prec:{precision:.4f}\")\n",
        "\n",
        "    # test_loss /= num_batches\n",
        "    # correct /= size\n",
        "    # print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "K8tSi8TZFQyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CONFIG"
      ],
      "metadata": {
        "id": "wmFzeBC6qaHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# HyperParams----Config.py\n",
        "hidden_size = 16\n",
        "output_size = 2\n",
        "\n",
        "learning_rate = 1e-3\n",
        "weight_decay = 5e-4\n",
        "batch_size = 64\n",
        "epochs = 50\n",
        "num_epochs_to_print = epochs/10                                                 # 每隔10次输出一次Metrics\n",
        "\n",
        "num_train = 8000\n",
        "num_test = num_patents - num_train"
      ],
      "metadata": {
        "id": "jKlYsn2aqdjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main"
      ],
      "metadata": {
        "id": "DgQRy866G5JW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MLP"
      ],
      "metadata": {
        "id": "m0KrE7E6LDCr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PIPLINE\n",
        "# DATA TO FIT A MODEL\n",
        "dataset = PatDataset(raw_data=raw_data, txt_vecs = Txt_Embedding)\n",
        "training_indices = [i for i in range(num_train)]\n",
        "test_indices = [i for i in range(num_train,num_train+num_test)]\n",
        "training_data_all = Subset(dataset, training_indices)\n",
        "test_data = Subset(dataset, test_indices)\n",
        "\n",
        "# Make pos:neg in training set 1:1\n",
        "pos_indices = []\n",
        "neg_indices = []\n",
        "for i in range(num_train):\n",
        "    if training_data_all[i][1] == 1:\n",
        "        pos_indices.append(i)\n",
        "    else:\n",
        "        neg_indices.append(i)\n",
        "num_pos = len(pos_indices)\n",
        "num_neg = len(neg_indices)\n",
        "print(f\"NEG:POS = {num_neg}:{num_pos} = {num_neg/num_pos:.2f}\")\n",
        "neg_indices_sample = np.random.choice(neg_indices, num_pos, replace = False)\t \n",
        "training_data_pos = Subset(training_data_all, pos_indices)\n",
        "training_data_neg = Subset(training_data_all, neg_indices_sample)\n",
        "training_data = ConcatDataset([training_data_pos, training_data_neg])\n",
        "print(\"Training sample number:\",len(training_data))\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")"
      ],
      "metadata": {
        "id": "Cnjn-MyeOvYq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4fe3de3-1835-4b54-d79b-1a9bd1dd552d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEG:POS = 6631:1369 = 4.84\n",
            "Training sample number: 2738\n",
            "Feature batch shape: torch.Size([64, 773])\n",
            "Labels batch shape: torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FIT A MODEL\n",
        "# PyTorch的逻辑是先初始化（喂超参），再进行函数计算（喂输入）\n",
        "input_size = len(dataset[0][0])\n",
        "model = SimpleNet(input_size, hidden_size, output_size).to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "for t in range(epochs):\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "    if t==0 or (t+1)%num_epochs_to_print == 0:\n",
        "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "        test_loop(train_dataloader, model, loss_fn)                                 # performance on training data\n",
        "        test_loop(test_dataloader, model, loss_fn)                                  # performance on test data\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "id": "iZiFY_jDIhNQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "791b46c8-4aa2-412c-f990-c1f4575813ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "[[ 255 1114]\n",
            " [ 102 1267]]\n",
            "29.5229\n",
            "acc:0.5559, f1:0.6757, recall:0.9255, prec:0.5321\n",
            "[[ 259 1295]\n",
            " [  38  401]]\n",
            "22.7404\n",
            "acc:0.3312, f1:0.3756, recall:0.9134, prec:0.2364\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "[[929 440]\n",
            " [536 833]]\n",
            "27.2733\n",
            "acc:0.6435, f1:0.6306, recall:0.6085, prec:0.6544\n",
            "[[951 603]\n",
            " [174 265]]\n",
            "21.2183\n",
            "acc:0.6101, f1:0.4055, recall:0.6036, prec:0.3053\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "[[873 496]\n",
            " [414 955]]\n",
            "26.4071\n",
            "acc:0.6676, f1:0.6773, recall:0.6976, prec:0.6582\n",
            "[[873 681]\n",
            " [148 291]]\n",
            "22.2760\n",
            "acc:0.5840, f1:0.4125, recall:0.6629, prec:0.2994\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "[[975 394]\n",
            " [465 904]]\n",
            "25.5535\n",
            "acc:0.6863, f1:0.6779, recall:0.6603, prec:0.6965\n",
            "[[961 593]\n",
            " [167 272]]\n",
            "21.2876\n",
            "acc:0.6187, f1:0.4172, recall:0.6196, prec:0.3145\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "[[908 461]\n",
            " [391 978]]\n",
            "24.8267\n",
            "acc:0.6888, f1:0.6966, recall:0.7144, prec:0.6796\n",
            "[[878 676]\n",
            " [160 279]]\n",
            "22.3954\n",
            "acc:0.5805, f1:0.4003, recall:0.6355, prec:0.2921\n",
            "Epoch 50\n",
            "-------------------------------\n",
            "[[1085  284]\n",
            " [ 521  848]]\n",
            "24.4738\n",
            "acc:0.7060, f1:0.6781, recall:0.6194, prec:0.7491\n",
            "[[1044  510]\n",
            " [ 186  253]]\n",
            "20.7150\n",
            "acc:0.6508, f1:0.4210, recall:0.5763, prec:0.3316\n",
            "Epoch 60\n",
            "-------------------------------\n",
            "[[ 793  576]\n",
            " [ 226 1143]]\n",
            "24.1480\n",
            "acc:0.7071, f1:0.7403, recall:0.8349, prec:0.6649\n",
            "[[684 870]\n",
            " [115 324]]\n",
            "25.6217\n",
            "acc:0.5058, f1:0.3968, recall:0.7380, prec:0.2714\n",
            "Epoch 70\n",
            "-------------------------------\n",
            "[[1001  368]\n",
            " [ 385  984]]\n",
            "23.3355\n",
            "acc:0.7250, f1:0.7233, recall:0.7188, prec:0.7278\n",
            "[[919 635]\n",
            " [167 272]]\n",
            "23.0185\n",
            "acc:0.5976, f1:0.4042, recall:0.6196, prec:0.2999\n",
            "Epoch 80\n",
            "-------------------------------\n",
            "[[1188  181]\n",
            " [ 629  740]]\n",
            "23.8035\n",
            "acc:0.7042, f1:0.6463, recall:0.5405, prec:0.8035\n",
            "[[1157  397]\n",
            " [ 231  208]]\n",
            "20.0182\n",
            "acc:0.6849, f1:0.3985, recall:0.4738, prec:0.3438\n",
            "Epoch 90\n",
            "-------------------------------\n",
            "[[ 979  390]\n",
            " [ 294 1075]]\n",
            "22.2430\n",
            "acc:0.7502, f1:0.7586, recall:0.7852, prec:0.7338\n",
            "[[869 685]\n",
            " [143 296]]\n",
            "23.9400\n",
            "acc:0.5845, f1:0.4169, recall:0.6743, prec:0.3017\n",
            "Epoch 100\n",
            "-------------------------------\n",
            "[[1175  194]\n",
            " [ 529  840]]\n",
            "22.3483\n",
            "acc:0.7359, f1:0.6991, recall:0.6136, prec:0.8124\n",
            "[[1102  452]\n",
            " [ 217  222]]\n",
            "20.4412\n",
            "acc:0.6643, f1:0.3989, recall:0.5057, prec:0.3294\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyG GNN"
      ],
      "metadata": {
        "id": "HZwU5sBFyly0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data.x, data.y\n",
        "for i in range(num_patents):\n",
        "    if i == 0:\n",
        "        x = dataset[i][0].unsqueeze(0)\n",
        "        y = dataset[i][1].unsqueeze(0)\n",
        "    else:\n",
        "        x = torch.cat([x, dataset[i][0].unsqueeze(0)])\n",
        "        y = torch.cat([y, dataset[i][1].unsqueeze(0)])\n",
        "\n",
        "print(x.shape, x.dtype, y.shape, y.dtype)"
      ],
      "metadata": {
        "id": "l_QEOKU8Pj6Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60ab89fa-a5e5-494c-a6be-ef7f2e74c0f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([9993, 773]) torch.float32 torch.Size([9993]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(pos_indices),len(neg_indices_sample))\n",
        "print(neg_indices_sample)"
      ],
      "metadata": {
        "id": "7gcVPUeMMurI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import Data\n",
        "\n",
        "# num_nodes, num_node_features\n",
        "x = torch.tensor(x, dtype=torch.float32)\n",
        "\n",
        "# num_nodes, 1\n",
        "y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "# 2, num_edges\n",
        "edge_index = torch.tensor(adj_ls, dtype=torch.long)\n",
        "\n",
        "# num_edges, num_edge_features\n",
        "edge_attr = torch.tensor(edges, dtype=torch.float32)\n",
        "\n",
        "# train-test split\n",
        "train_ls = [False]*num_train + [False]*num_test\n",
        "train_mask = torch.tensor(train_ls, dtype=bool)\n",
        "train_mask[pos_indices] = True\n",
        "train_mask[neg_indices_sample] = True\n",
        "test_ls = [False]*num_train + [True]*num_test\n",
        "test_mask = torch.tensor(test_ls, dtype=bool)\n",
        "\n",
        "\n",
        "data = Data(x=x, y=y, edge_index = edge_index.t().contiguous(), edge_attr=edge_attr, train_mask = train_mask, test_mask=test_mask)\n",
        "data = data.to(device)"
      ],
      "metadata": {
        "id": "fXfkKRT6CGHV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e5de33c-3e9d-4e1f-d7fc-9c103754255f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Number of nodes: {data.num_nodes}') # 节点数量\n",
        "print(f'Number of edges: {data.num_edges}') # 边数量\n",
        "print(f'Number of node features: {data.num_node_features}') # 节点属性的维度\n",
        "print(f'Number of node features: {data.num_features}') # 同样是节点属性的维度\n",
        "print(f'Number of edge features: {data.num_edge_features}') # 边属性的维度\n",
        "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}') # 平均节点度\n",
        "print(f'if edge indices are ordered and do not contain duplicate entries.: {data.is_coalesced()}') # 是否边是有序的同时不含有重复的边\n",
        "print(f'Number of training nodes: {data.train_mask.sum()}') # 用作训练集的节点\n",
        "print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}') # 用作训练集的节点的数量\n",
        "print(f'Contains isolated nodes: {data.has_isolated_nodes()}') # 此图是否包含孤立的节点\n",
        "print(f'Contains self-loops: {data.has_self_loops()}')  # 此图是否包含自环的边\n",
        "print(f'Is undirected: {data.is_undirected()}')  # 此图是否是无向图"
      ],
      "metadata": {
        "id": "tfxaz5LtCGFC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eafadc72-ae8b-47f8-ecba-038854782729"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of nodes: 9993\n",
            "Number of edges: 5560\n",
            "Number of node features: 773\n",
            "Number of node features: 773\n",
            "Number of edge features: 1\n",
            "Average node degree: 0.56\n",
            "if edge indices are ordered and do not contain duplicate entries.: True\n",
            "Number of training nodes: 2738\n",
            "Training node label rate: 0.27\n",
            "Contains isolated nodes: True\n",
            "Contains self-loops: False\n",
            "Is undirected: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = len(dataset[0][0])\n",
        "\n",
        "model = GNN(input_size, hidden_size, output_size).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "model.train()\n",
        "for epoch in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data)\n",
        "    loss = loss_fn(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "cCx5_Hl5CGCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "pred = model(data).argmax(dim=1)\n",
        "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
        "acc = int(correct) / int(data.test_mask.sum())\n",
        "print(f'Accuracy: {acc:.4f}')\n",
        "Pred = pred[data.test_mask].cpu()\n",
        "Y = data.y[data.test_mask].cpu()\n",
        "C_Mat = metrics.confusion_matrix(Y, Pred)\n",
        "accuracy = metrics.accuracy_score(Y,Pred)\n",
        "f1 = metrics.f1_score(Y, Pred)\n",
        "recall = metrics.recall_score(Y, Pred)\n",
        "precision = metrics.precision_score(Y, Pred)\n",
        "print(C_Mat)\n",
        "print(f\"acc:{accuracy:.4f}, f1:{f1:.4f}, recall:{recall:.4f}, prec:{precision:.4f}\")\n"
      ],
      "metadata": {
        "id": "D44a9N5TCF6D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb67d80a-037b-4553-8fd2-e2dc5f9b9f4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6754\n",
            "[[1143  411]\n",
            " [ 236  203]]\n",
            "acc:0.6754, f1:0.3856, recall:0.4624, prec:0.3306\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save&Load Model"
      ],
      "metadata": {
        "id": "VNIQr9XuakxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 保存模型权重至当前文件夹\n",
        "torch.save(model.state_dict(), 'model_weights.pth')                             "
      ],
      "metadata": {
        "id": "tTO_IOiiarkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleNet(input_size, hidden_size, output_size)                         # 需要是同一个模型\n",
        "model.load_state_dict(torch.load('model_weights.pth'))\n",
        "model.eval()\n",
        "\n",
        "'''\n",
        "be sure to call model.eval() method before inferencing to set the dropout and batch normalization layers to evaluation mode. \n",
        "Failing to do this will yield inconsistent inference results.\n",
        "'''"
      ],
      "metadata": {
        "id": "nQejY8J8ay0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 直接保存/加载整个模型\n",
        "torch.save(model, 'model.pth')"
      ],
      "metadata": {
        "id": "u0CxBdcFdJkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('model.pth')"
      ],
      "metadata": {
        "id": "7HujEzt6d9k-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PISkr-lNd_iH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discoveries\n",
        "1. SimpleNet的训练情况似乎说明**模型并不能从数据中学到什么东西（特征可能没有提供什么信息）**。\n",
        "线性模型和MLP跑出来几乎没差别，说明问题不在模型上面，基本可以断定是数据（输入特征）的问题。"
      ],
      "metadata": {
        "id": "6GSfZNi978Mu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. GNN的训练好像比SimpleNet快很多，可能是train_loop写得太复杂了。"
      ],
      "metadata": {
        "id": "NzEJ90CXhX_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = raw_data[\"patent_title\"].values[0] +\" \" +raw_data[\"patent_abstract\"].values[0]\n",
        "\n"
      ],
      "metadata": {
        "id": "AXbkrbORciD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = tokenizer(t, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "Bt1SjH-kQD69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i, i.input_ids[0, :128]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maB48nxZQ6Ug",
        "outputId": "daa5b6d2-5b26-45a3-da80-28431310c89a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'input_ids': tensor([[  101,  5217,  9419,  1998,  4316, 16636,  2075, 14709,  2005,  6882,\n",
              "           5217,  9378,  2545,  2019,  9935, 16636,  2953,  2005,  2224,  1999,\n",
              "           9595,  2007,  1037,  5217,  9419,  5080,  2005,  2019,  6882,  5217,\n",
              "           9378,  2121,  2164,  2019, 10866,  4677,  2383,  1037, 29018,  1997,\n",
              "          13228,  2135,  8526,  3085,  6077, 20369,  2135,  7119,  2045,  3406,\n",
              "           1012,  1996,  6077,  5373,  3604,  1999,  1037,  2597,  2000,  9075,\n",
              "           2019,  8285,  2083,  1996,  9378,  2121,  2073,  4017,  1996,  2041,\n",
              "           6277,  2203,  2003,  1999,  2485,  2523,  2007,  1996,  4677,  1998,\n",
              "           4218,  1996,  9935,  2034,  4637,  3302,  1012,  4082,  2965,  2024,\n",
              "           2443, 13557,  2043,  2019,  9935,  2003,  1999,  2597,  2012,  2560,\n",
              "           2028,  1997,  1996,  6077,  2097,  2022,  8073,  2333,  2000,  1037,\n",
              "           2597,  2073,  1996,  3899,  8908,  2682,  1996,  9935,  4637,  3302,\n",
              "           1010, 10402,  1037,  5217,  1010,  1998, 23876,  1996,  2482,  2083,\n",
              "           1996,  9378,  2121, 14709,  1012,  2012,  1996,  5217,  9419,  1998,\n",
              "          12699,  2276,  1996,  4677,  2003,  3140, 14047,  2135,  2000,  1037,\n",
              "           2597,  2073,  4017,  2009,  5235,  4218,  1996,  7337,  4072,  2000,\n",
              "           4685,  1996,  5217,  9419,  3169,  2096,  2145, 12823,  1996,  2041,\n",
              "           6277,  2203,  1997,  1996,  3899,  2682,  1996,  9935,  4637,  3302,\n",
              "           1012,  1996, 27222,  3967,  2011,  1996,  3899, 14306,  2015,  2008,\n",
              "           1996,  9935,  5829,  2083,  1996,  9378,  2121, 14709,  1999,  1037,\n",
              "           7142,  4367,  1012,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])},\n",
              " tensor([  101,  5217,  9419,  1998,  4316, 16636,  2075, 14709,  2005,  6882,\n",
              "          5217,  9378,  2545,  2019,  9935, 16636,  2953,  2005,  2224,  1999,\n",
              "          9595,  2007,  1037,  5217,  9419,  5080,  2005,  2019,  6882,  5217,\n",
              "          9378,  2121,  2164,  2019, 10866,  4677,  2383,  1037, 29018,  1997,\n",
              "         13228,  2135,  8526,  3085,  6077, 20369,  2135,  7119,  2045,  3406,\n",
              "          1012,  1996,  6077,  5373,  3604,  1999,  1037,  2597,  2000,  9075,\n",
              "          2019,  8285,  2083,  1996,  9378,  2121,  2073,  4017,  1996,  2041,\n",
              "          6277,  2203,  2003,  1999,  2485,  2523,  2007,  1996,  4677,  1998,\n",
              "          4218,  1996,  9935,  2034,  4637,  3302,  1012,  4082,  2965,  2024,\n",
              "          2443, 13557,  2043,  2019,  9935,  2003,  1999,  2597,  2012,  2560,\n",
              "          2028,  1997,  1996,  6077,  2097,  2022,  8073,  2333,  2000,  1037,\n",
              "          2597,  2073,  1996,  3899,  8908,  2682,  1996,  9935,  4637,  3302,\n",
              "          1010, 10402,  1037,  5217,  1010,  1998, 23876,  1996]))"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "KrhGZ_qxRP5A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}