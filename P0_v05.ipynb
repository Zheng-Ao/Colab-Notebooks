{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "P0_v05.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "fKdAJ8l5F_yg",
        "X_w0ItLna28l",
        "eFTDdD4jgSP3",
        "wmFzeBC6qaHX",
        "m0KrE7E6LDCr",
        "HZwU5sBFyly0",
        "VNIQr9XuakxG",
        "6GSfZNi978Mu"
      ],
      "mount_file_id": "1Sqr4KjJKKhLBjnKrl_PrfHPUOMsYKDXX",
      "authorship_tag": "ABX9TyP89tCZrHEYB+1p2ueU1z4a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zheng-Ao/Colab-Notebooks/blob/main/P0_v05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# library install & cuda device"
      ],
      "metadata": {
        "id": "fKdAJ8l5F_yg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CR_-xEl5Emv2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a84698d-8c14-4c27-c3ce-98d09a7e8c3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.12.0+cu113\n",
            "11.3\n"
          ]
        }
      ],
      "source": [
        "!python -c \"import torch; print(torch.__version__)\"\n",
        "!python -c \"import torch; print(torch.version.cuda)\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-1.12.0+cu113.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-1.12.0+cu113.html\n",
        "!pip install torch-geometric"
      ],
      "metadata": {
        "id": "q_Zxt-SIFo9U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1828be2c-b42c-4218-a43b-ad440a0286f8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.21.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.12.0+cu113.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.7/dist-packages (2.0.9)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.12.0+cu113.html\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.7/dist-packages (0.6.14)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.7/dist-packages (2.0.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.7.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.64.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.3.5)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n",
        "import torch\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "import pandas as pd\n",
        "raw_data_path = \"drive/MyDrive/P0/T10K.csv\"\n",
        "\n",
        "pd.read_csv(raw_data_path)"
      ],
      "metadata": {
        "id": "nCiAU3vwGSlo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f4b82932-b060-493e-f901-9a13578a4ed9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jul 30 08:37:08 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   73C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0 patent_number patent_date  patent_num_cited_by_us_patents  \\\n",
              "0              0       3930276  1976-01-06                               4   \n",
              "1              1       3930279  1976-01-06                               5   \n",
              "2              2       3930323  1976-01-06                              17   \n",
              "3              3       3930526  1976-01-06                              14   \n",
              "4              4       3930527  1976-01-06                              19   \n",
              "...          ...           ...         ...                             ...   \n",
              "9995        9995       4358129  1982-11-09                               1   \n",
              "9996        9996       4358133  1982-11-09                              32   \n",
              "9997        9997       4358135  1982-11-09                              22   \n",
              "9998        9998       4358136  1982-11-09                              32   \n",
              "9999        9999       4358148  1982-11-09                               4   \n",
              "\n",
              "                                           patent_title  \\\n",
              "0     Wheel spinning and vehicle conveying apparatus...   \n",
              "1     Rubber windshield wiper blades having increase...   \n",
              "2     Chain tensioning mechanism for scraper elevato...   \n",
              "3                   Pneumatic tire and wheel assemblies   \n",
              "4                               Tire and wheel assembly   \n",
              "...                                                 ...   \n",
              "9995  Tractor with a built-on underframe for a tilli...   \n",
              "9996                           Adjustable width trailer   \n",
              "9997   Connector for igniting circuit of priming device   \n",
              "9998  Energy absorbing device for use with vehicular...   \n",
              "9999                               Damped railway wheel   \n",
              "\n",
              "                                        patent_abstract  patent_num_claims  \\\n",
              "0     An automobile conveyor for use in conjunction ...                 12   \n",
              "1     A rubber windshield wiper blade is clamped to ...                  2   \n",
              "2     A tensioning mechanism for the chain of a scra...                  2   \n",
              "3     A pneumatic tire and wheel assembly comprises ...                 21   \n",
              "4     A wheel having a pair of spaced-apart seats fo...                  8   \n",
              "...                                                 ...                ...   \n",
              "9995  The back part of the underframe is fastened to...                  2   \n",
              "9996  A trailer frame having fixed wheel track is pr...                  6   \n",
              "9997  A connector provided in an igniting circuit fo...                  9   \n",
              "9998  An energy absorbing device for use with a vehi...                  7   \n",
              "9999  A vibration damping assembly for a wheel or th...                  8   \n",
              "\n",
              "      patent_num_us_patent_citations  \\\n",
              "0                                  2   \n",
              "1                                  3   \n",
              "2                                  4   \n",
              "3                                  7   \n",
              "4                                 13   \n",
              "...                              ...   \n",
              "9995                               4   \n",
              "9996                               6   \n",
              "9997                               7   \n",
              "9998                               7   \n",
              "9999                              10   \n",
              "\n",
              "                                              inventors  \\\n",
              "0     [{'inventor_sequence': '0', 'inventor_key_id':...   \n",
              "1     [{'inventor_sequence': '0', 'inventor_key_id':...   \n",
              "2     [{'inventor_sequence': '0', 'inventor_key_id':...   \n",
              "3     [{'inventor_sequence': '0', 'inventor_key_id':...   \n",
              "4     [{'inventor_sequence': '0', 'inventor_key_id':...   \n",
              "...                                                 ...   \n",
              "9995  [{'inventor_sequence': '0', 'inventor_key_id':...   \n",
              "9996  [{'inventor_sequence': '0', 'inventor_key_id':...   \n",
              "9997  [{'inventor_sequence': '0', 'inventor_key_id':...   \n",
              "9998  [{'inventor_sequence': '0', 'inventor_key_id':...   \n",
              "9999  [{'inventor_sequence': '0', 'inventor_key_id':...   \n",
              "\n",
              "                                              assignees  \\\n",
              "0     [{'assignee_sequence': '0', 'assignee_key_id':...   \n",
              "1     [{'assignee_sequence': None, 'assignee_key_id'...   \n",
              "2     [{'assignee_sequence': '0', 'assignee_key_id':...   \n",
              "3     [{'assignee_sequence': '0', 'assignee_key_id':...   \n",
              "4     [{'assignee_sequence': '0', 'assignee_key_id':...   \n",
              "...                                                 ...   \n",
              "9995  [{'assignee_sequence': None, 'assignee_key_id'...   \n",
              "9996  [{'assignee_sequence': None, 'assignee_key_id'...   \n",
              "9997  [{'assignee_sequence': '0', 'assignee_key_id':...   \n",
              "9998  [{'assignee_sequence': '0', 'assignee_key_id':...   \n",
              "9999  [{'assignee_sequence': '0', 'assignee_key_id':...   \n",
              "\n",
              "                                                   IPCs  \\\n",
              "0                               [{'ipc_sequence': '0'}]   \n",
              "1                               [{'ipc_sequence': '0'}]   \n",
              "2        [{'ipc_sequence': '0'}, {'ipc_sequence': '1'}]   \n",
              "3                               [{'ipc_sequence': '0'}]   \n",
              "4     [{'ipc_sequence': '0'}, {'ipc_sequence': '1'},...   \n",
              "...                                                 ...   \n",
              "9995                            [{'ipc_sequence': '0'}]   \n",
              "9996                            [{'ipc_sequence': '0'}]   \n",
              "9997     [{'ipc_sequence': '0'}, {'ipc_sequence': '1'}]   \n",
              "9998                            [{'ipc_sequence': '0'}]   \n",
              "9999  [{'ipc_sequence': '0'}, {'ipc_sequence': '1'},...   \n",
              "\n",
              "                                          cited_patents  \n",
              "0     [{'cited_patent_number': '3037223', 'cited_pat...  \n",
              "1     [{'cited_patent_number': '2140453', 'cited_pat...  \n",
              "2     [{'cited_patent_number': '372157', 'cited_pate...  \n",
              "3     [{'cited_patent_number': '1359461', 'cited_pat...  \n",
              "4     [{'cited_patent_number': '1921772', 'cited_pat...  \n",
              "...                                                 ...  \n",
              "9995  [{'cited_patent_number': '2707643', 'cited_pat...  \n",
              "9996  [{'cited_patent_number': '3239274', 'cited_pat...  \n",
              "9997  [{'cited_patent_number': '3509297', 'cited_pat...  \n",
              "9998  [{'cited_patent_number': '3547468', 'cited_pat...  \n",
              "9999  [{'cited_patent_number': '734417', 'cited_pate...  \n",
              "\n",
              "[10000 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-52382b1f-7f28-4a66-821d-99bdf4ac6ba6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>patent_number</th>\n",
              "      <th>patent_date</th>\n",
              "      <th>patent_num_cited_by_us_patents</th>\n",
              "      <th>patent_title</th>\n",
              "      <th>patent_abstract</th>\n",
              "      <th>patent_num_claims</th>\n",
              "      <th>patent_num_us_patent_citations</th>\n",
              "      <th>inventors</th>\n",
              "      <th>assignees</th>\n",
              "      <th>IPCs</th>\n",
              "      <th>cited_patents</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3930276</td>\n",
              "      <td>1976-01-06</td>\n",
              "      <td>4</td>\n",
              "      <td>Wheel spinning and vehicle conveying apparatus...</td>\n",
              "      <td>An automobile conveyor for use in conjunction ...</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>[{'inventor_sequence': '0', 'inventor_key_id':...</td>\n",
              "      <td>[{'assignee_sequence': '0', 'assignee_key_id':...</td>\n",
              "      <td>[{'ipc_sequence': '0'}]</td>\n",
              "      <td>[{'cited_patent_number': '3037223', 'cited_pat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3930279</td>\n",
              "      <td>1976-01-06</td>\n",
              "      <td>5</td>\n",
              "      <td>Rubber windshield wiper blades having increase...</td>\n",
              "      <td>A rubber windshield wiper blade is clamped to ...</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>[{'inventor_sequence': '0', 'inventor_key_id':...</td>\n",
              "      <td>[{'assignee_sequence': None, 'assignee_key_id'...</td>\n",
              "      <td>[{'ipc_sequence': '0'}]</td>\n",
              "      <td>[{'cited_patent_number': '2140453', 'cited_pat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3930323</td>\n",
              "      <td>1976-01-06</td>\n",
              "      <td>17</td>\n",
              "      <td>Chain tensioning mechanism for scraper elevato...</td>\n",
              "      <td>A tensioning mechanism for the chain of a scra...</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>[{'inventor_sequence': '0', 'inventor_key_id':...</td>\n",
              "      <td>[{'assignee_sequence': '0', 'assignee_key_id':...</td>\n",
              "      <td>[{'ipc_sequence': '0'}, {'ipc_sequence': '1'}]</td>\n",
              "      <td>[{'cited_patent_number': '372157', 'cited_pate...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3930526</td>\n",
              "      <td>1976-01-06</td>\n",
              "      <td>14</td>\n",
              "      <td>Pneumatic tire and wheel assemblies</td>\n",
              "      <td>A pneumatic tire and wheel assembly comprises ...</td>\n",
              "      <td>21</td>\n",
              "      <td>7</td>\n",
              "      <td>[{'inventor_sequence': '0', 'inventor_key_id':...</td>\n",
              "      <td>[{'assignee_sequence': '0', 'assignee_key_id':...</td>\n",
              "      <td>[{'ipc_sequence': '0'}]</td>\n",
              "      <td>[{'cited_patent_number': '1359461', 'cited_pat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>3930527</td>\n",
              "      <td>1976-01-06</td>\n",
              "      <td>19</td>\n",
              "      <td>Tire and wheel assembly</td>\n",
              "      <td>A wheel having a pair of spaced-apart seats fo...</td>\n",
              "      <td>8</td>\n",
              "      <td>13</td>\n",
              "      <td>[{'inventor_sequence': '0', 'inventor_key_id':...</td>\n",
              "      <td>[{'assignee_sequence': '0', 'assignee_key_id':...</td>\n",
              "      <td>[{'ipc_sequence': '0'}, {'ipc_sequence': '1'},...</td>\n",
              "      <td>[{'cited_patent_number': '1921772', 'cited_pat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>9995</td>\n",
              "      <td>4358129</td>\n",
              "      <td>1982-11-09</td>\n",
              "      <td>1</td>\n",
              "      <td>Tractor with a built-on underframe for a tilli...</td>\n",
              "      <td>The back part of the underframe is fastened to...</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>[{'inventor_sequence': '0', 'inventor_key_id':...</td>\n",
              "      <td>[{'assignee_sequence': None, 'assignee_key_id'...</td>\n",
              "      <td>[{'ipc_sequence': '0'}]</td>\n",
              "      <td>[{'cited_patent_number': '2707643', 'cited_pat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>9996</td>\n",
              "      <td>4358133</td>\n",
              "      <td>1982-11-09</td>\n",
              "      <td>32</td>\n",
              "      <td>Adjustable width trailer</td>\n",
              "      <td>A trailer frame having fixed wheel track is pr...</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>[{'inventor_sequence': '0', 'inventor_key_id':...</td>\n",
              "      <td>[{'assignee_sequence': None, 'assignee_key_id'...</td>\n",
              "      <td>[{'ipc_sequence': '0'}]</td>\n",
              "      <td>[{'cited_patent_number': '3239274', 'cited_pat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>9997</td>\n",
              "      <td>4358135</td>\n",
              "      <td>1982-11-09</td>\n",
              "      <td>22</td>\n",
              "      <td>Connector for igniting circuit of priming device</td>\n",
              "      <td>A connector provided in an igniting circuit fo...</td>\n",
              "      <td>9</td>\n",
              "      <td>7</td>\n",
              "      <td>[{'inventor_sequence': '0', 'inventor_key_id':...</td>\n",
              "      <td>[{'assignee_sequence': '0', 'assignee_key_id':...</td>\n",
              "      <td>[{'ipc_sequence': '0'}, {'ipc_sequence': '1'}]</td>\n",
              "      <td>[{'cited_patent_number': '3509297', 'cited_pat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>9998</td>\n",
              "      <td>4358136</td>\n",
              "      <td>1982-11-09</td>\n",
              "      <td>32</td>\n",
              "      <td>Energy absorbing device for use with vehicular...</td>\n",
              "      <td>An energy absorbing device for use with a vehi...</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>[{'inventor_sequence': '0', 'inventor_key_id':...</td>\n",
              "      <td>[{'assignee_sequence': '0', 'assignee_key_id':...</td>\n",
              "      <td>[{'ipc_sequence': '0'}]</td>\n",
              "      <td>[{'cited_patent_number': '3547468', 'cited_pat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>9999</td>\n",
              "      <td>4358148</td>\n",
              "      <td>1982-11-09</td>\n",
              "      <td>4</td>\n",
              "      <td>Damped railway wheel</td>\n",
              "      <td>A vibration damping assembly for a wheel or th...</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>[{'inventor_sequence': '0', 'inventor_key_id':...</td>\n",
              "      <td>[{'assignee_sequence': '0', 'assignee_key_id':...</td>\n",
              "      <td>[{'ipc_sequence': '0'}, {'ipc_sequence': '1'},...</td>\n",
              "      <td>[{'cited_patent_number': '734417', 'cited_pate...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-52382b1f-7f28-4a66-821d-99bdf4ac6ba6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-52382b1f-7f28-4a66-821d-99bdf4ac6ba6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-52382b1f-7f28-4a66-821d-99bdf4ac6ba6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# utils.py"
      ],
      "metadata": {
        "id": "F_Rn1K8pE3Z0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Txt2Vec Matrix, PCA"
      ],
      "metadata": {
        "id": "X_w0ItLna28l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data_path = \"drive/MyDrive/P0/T10K.csv\"\n",
        "\n",
        "# 构建出txt_vecs，作为Dataset的第二个数据来源\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "from transformers import DistilBertTokenizer, DistilBertModel\n",
        "\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")      \n",
        "nlp_model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\").to(device)\n",
        "\n",
        "'''加载BERT这种大模型很耗时，因此在整个流程中应当让上面两行代码只执行一次。'''\n",
        "\n",
        "\n",
        "df = pd.read_csv(raw_data_path)\n",
        "\n",
        "for i in tqdm(range(10000)):\n",
        "    ttl = df[\"patent_title\"].values[i]\n",
        "    inputs = tokenizer(ttl, return_tensors=\"pt\").to(device)\n",
        "    outputs = nlp_model(**inputs)\n",
        "    last_hidden_states = outputs.last_hidden_state\n",
        "    cls_vec = last_hidden_states[:,0,:].clone().detach()\n",
        "    if i == 0:\n",
        "        txt_vecs = cls_vec\n",
        "    else:\n",
        "        txt_vecs = torch.cat([txt_vecs, cls_vec],dim=0)"
      ],
      "metadata": {
        "id": "TjwGItGlE5Eh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7da71ef-344d-4bb4-be92-9aa4a72d9b2b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "100%|██████████| 10000/10000 [01:09<00:00, 143.08it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# txt_vecs.shape"
      ],
      "metadata": {
        "id": "WqiAYwXBdZoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Mat = txt_vecs.cpu().numpy()"
      ],
      "metadata": {
        "id": "wUIQrsOSb0X4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mat.shape"
      ],
      "metadata": {
        "id": "qCNKg7S-gnio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "E_SqxF1chNgz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# txt_pca = PCA(n_components=0.9, svd_solver = 'full')\n",
        "txt_pca = PCA(n_components = 5)"
      ],
      "metadata": {
        "id": "3dy2-_CGoCqp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# txt_pca.fit(Mat)\n",
        "# var = txt_pca.explained_variance_ratio_\n",
        "# len(var), var.sum()"
      ],
      "metadata": {
        "id": "CaoLuPwphNVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_Mat = txt_pca.fit_transform(Mat)"
      ],
      "metadata": {
        "id": "Wp1-4ZfciG91"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## utils"
      ],
      "metadata": {
        "id": "eFTDdD4jgSP3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, Subset, ConcatDataset, DataLoader\n",
        "from torch import nn\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn import metrics\n",
        "\n",
        "import random\n",
        "\n",
        "from datetime import datetime\n",
        "# target transform, 0:neg, 1:pos\n",
        "def LabelCorePa(ref, isd):\n",
        "    now = datetime.strptime(\"2022-01-01\", \"%Y-%m-%d\").year\n",
        "    years = now - datetime.strptime(isd, \"%Y-%m-%d\").year\n",
        "    score = ref/years       \n",
        "    label = int((score>0.5))\n",
        "    return label\n",
        "\n",
        "# Dataset\n",
        "class PatDataset(Dataset):\n",
        "    def __init__(self, raw_data_path, txt_vecs, transform = None, target_transform = LabelCorePa):\n",
        "        self.raw_data = pd.read_csv(raw_data_path)\n",
        "        self.txt_vecs = txt_vecs\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.raw_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Y          \n",
        "        ref = self.raw_data.at[idx, \"patent_num_cited_by_us_patents\"]\n",
        "        isd = self.raw_data.at[idx, \"patent_date\"]\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(ref, isd)\n",
        "            label = torch.tensor(label,dtype=torch.long)\n",
        "\n",
        "        # X\n",
        "        # INDEXs\n",
        "        num_claims = self.raw_data.at[idx, \"patent_num_claims\"]\n",
        "        num_b_cits = self.raw_data.at[idx, \"patent_num_us_patent_citations\"]\n",
        "        inventors = self.raw_data.at[idx, \"inventors\"]\n",
        "        num_inventors = len(eval(inventors))\n",
        "        assignees = self.raw_data.at[idx, \"assignees\"]\n",
        "        if assignees == \"[{'assignee_sequence': None, 'assignee_key_id': None}]\":\n",
        "            num_assignees = 0\n",
        "        else:\n",
        "            num_assignees = len(eval(assignees))\n",
        "        IPCs = self.raw_data.at[idx, \"IPCs\"]\n",
        "        num_ipcs = len(eval(IPCs))\n",
        "        indexs = torch.tensor([num_claims, num_b_cits, num_inventors, num_assignees, num_ipcs], dtype=torch.float32).to(device)\n",
        "        # TXT\n",
        "        txt_vec = torch.tensor(self.txt_vecs[idx], dtype = torch.float32)\n",
        "        txt_vec = txt_vec.to(device)\n",
        "\n",
        "        patent = torch.cat([indexs, txt_vec])\n",
        "        \n",
        "        return patent, label\n",
        "\n",
        "# Models\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(SimpleNet, self).__init__()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.BatchNorm1d(input_size),\n",
        "            nn.Linear(input_size, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, output_size),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "from torch_geometric.nn import GCNConv\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class GNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(GNN, self).__init__()\n",
        "        self.conv1 = GCNConv(input_size, hidden_size)\n",
        "        self.conv2 = GCNConv(hidden_size, 2)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        logits = self.conv2(x, edge_index)                   # (num_nodes, 2)\n",
        "        return logits                  # (num_nodes, 2)\n",
        "\n",
        "\n",
        "\n",
        "# Train\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "\n",
        "        # batch: 第几个batch；X: 包含batch_size个feature vec.\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        output = model(X).to(device)\n",
        "        loss = loss_fn(output, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 20 == 0:                                                     # train_size/batch_size = 100, 每20个batch输出一次结果，共输出5次。\n",
        "            loss, current = loss.item(), batch * len(X)                         \n",
        "            # print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "# Test\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch, (X, y) in enumerate(dataloader):\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            output = model(X)\n",
        "            # test_loss += loss_fn(output, y).item()\n",
        "            # correct += (output.argmax(1) == y).type(torch.float).sum().item()\n",
        "            \n",
        "            pred = output.argmax(1).cpu()\n",
        "            y = y.cpu()\n",
        "            if batch == 0:\n",
        "                Pred = pred\n",
        "                Y = y\n",
        "            else:\n",
        "                Pred = torch.cat((Pred, pred), dim = 0)\n",
        "                Y = torch.cat((Y, y), dim=0)\n",
        "\n",
        "    C_Mat = metrics.confusion_matrix(Y, Pred)\n",
        "    accuracy = metrics.accuracy_score(Y,Pred)\n",
        "    f1 = metrics.f1_score(Y, Pred)\n",
        "    recall = metrics.recall_score(Y, Pred)\n",
        "    precision = metrics.precision_score(Y, Pred)\n",
        "    print(C_Mat)\n",
        "    print(f\"acc:{accuracy:.4f}, f1:{f1:.4f}, recall:{recall:.4f}, prec:{precision:.4f}\")\n",
        "\n",
        "    # test_loss /= num_batches\n",
        "    # correct /= size\n",
        "    # print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "K8tSi8TZFQyB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# config.py"
      ],
      "metadata": {
        "id": "wmFzeBC6qaHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# HyperParams----Config.py\n",
        "hidden_size = 32\n",
        "output_size = 2\n",
        "\n",
        "learning_rate = 1e-3\n",
        "weight_decay = 5e-4\n",
        "batch_size = 64                                                                 # test_size/batch_size = 25, 25 batches.\n",
        "epochs = 10\n",
        "\n",
        "num_train = 8000\n",
        "num_test = 2000"
      ],
      "metadata": {
        "id": "jKlYsn2aqdjS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main"
      ],
      "metadata": {
        "id": "DgQRy866G5JW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Net"
      ],
      "metadata": {
        "id": "m0KrE7E6LDCr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_Mat.shape"
      ],
      "metadata": {
        "id": "LKj3i6Uou6DJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd772d7b-608d-4ec2-a7fb-fbd18fc0cd43"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PIPLINE\n",
        "# DATA TO FIT A MODEL\n",
        "dataset = PatDataset(raw_data_path=raw_data_path, txt_vecs = new_Mat)\n",
        "training_indices = [i for i in range(num_train)]\n",
        "test_indices = [i for i in range(num_train,num_train+num_test)]\n",
        "training_data_all = Subset(dataset, training_indices)\n",
        "test_data = Subset(dataset, test_indices)\n",
        "\n",
        "# Make pos:neg in training set 1:1\n",
        "pos_indices = []\n",
        "neg_indices = []\n",
        "for i in range(num_train):\n",
        "    if training_data_all[i][1] == 1:\n",
        "        pos_indices.append(i)\n",
        "    else:\n",
        "        neg_indices.append(i)\n",
        "num_pos = len(pos_indices)\n",
        "num_neg = len(neg_indices)\n",
        "print(f\"{num_neg}:{num_pos} = {num_neg/num_pos}\")\n",
        "neg_indices_sample = np.random.choice(neg_indices, num_pos, replace = False)\t \n",
        "training_data_pos = Subset(training_data_all, pos_indices)\n",
        "training_data_neg = Subset(training_data_all, neg_indices_sample)\n",
        "training_data = ConcatDataset([training_data_pos, training_data_neg])\n",
        "print(\"Training sample number:\",len(training_data))\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")"
      ],
      "metadata": {
        "id": "Cnjn-MyeOvYq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cedc222-b3a6-408f-d6d5-51b191ced6fc"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6633:1367 = 4.852231163130944\n",
            "Training sample number: 2734\n",
            "Feature batch shape: torch.Size([64, 10])\n",
            "Labels batch shape: torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FIT A MODEL\n",
        "# PyTorch的逻辑是先初始化（喂超参），再进行函数计算（喂输入）\n",
        "input_size = len(dataset[0][0])\n",
        "model = SimpleNet(input_size, hidden_size, output_size).to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "    test_loop(train_dataloader, model, loss_fn)                                 # performance on training data\n",
        "    test_loop(test_dataloader, model, loss_fn)                                  # performance on test data\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "id": "iZiFY_jDIhNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyG GNN Net"
      ],
      "metadata": {
        "id": "HZwU5sBFyly0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# edge_index, edge_attr\n",
        "df = pd.read_csv(raw_data_path)\n",
        "\n",
        "adj_ls = []\n",
        "edges = []\n",
        "\n",
        "for i in tqdm(range(10000)):\n",
        "    id = df.values[i][0]\n",
        "    b_cits = eval(df[\"cited_patents\"].values[i])\n",
        "    for b_cit in b_cits:\n",
        "        # 是否在专利数据库中\n",
        "        if b_cit[\"cited_patent_date\"]:\n",
        "            # 是否在本数据集中\n",
        "            if b_cit[\"cited_patent_number\"] in df[\"patent_number\"].values:\n",
        "                # print(i)\n",
        "                cit_id = df[df[\"patent_number\"].values == b_cit[\"cited_patent_number\"]].values[0][0]\n",
        "                adj_ls.append([id, cit_id])\n",
        "                date = df[\"patent_date\"].values[id]\n",
        "                cit_date = df[\"patent_date\"].values[cit_id]\n",
        "                date1 = datetime.strptime(date, \"%Y-%m-%d\")\n",
        "                date2 = datetime.strptime(cit_date, \"%Y-%m-%d\")\n",
        "                dist = date1-date2\n",
        "                dist = 365/dist.days\n",
        "                edges.append(dist)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-myLjEp_2AHk",
        "outputId": "49f5b445-546c-4a78-aa6f-3b44842c5460"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10000/10000 [00:25<00:00, 384.99it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df[df[\"patent_number\"].values == '3930276'].values[0][0]\n",
        "# \"3930276\" in df[\"patent_number\"].values\n",
        "# edges\n",
        "ls = [i for i in range(10)]\n",
        "\n",
        "ls_1 = np.random.choice(ls,5, replace = False)\n",
        "ls_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xxur-qrM2SnT",
        "outputId": "5a60c6c0-b220-4f27-9a96-628876334d6d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 4, 0, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data.x, data.y\n",
        "for i in range(10000):\n",
        "    if i == 0:\n",
        "        x = dataset[i][0].unsqueeze(0)\n",
        "        y = dataset[i][1].unsqueeze(0)\n",
        "    else:\n",
        "        x = torch.cat([x, dataset[i][0].unsqueeze(0)])\n",
        "        y = torch.cat([y, dataset[i][1].unsqueeze(0)])\n",
        "\n",
        "# "
      ],
      "metadata": {
        "id": "JT6lZqVrIsnt"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape, x.dtype, y.shape, y.dtype"
      ],
      "metadata": {
        "id": "CtjHVuhNP3vn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(pos_indices),len(neg_indices_sample))\n",
        "print(neg_indices_sample)\n",
        "# len = 10\n",
        "# indices = [1,2,4,5]\n",
        " \n",
        "# ls1 = [False]*10\n",
        "# t = torch.tensor(ls1)\n",
        "# t[indices] = True\n",
        "# t\n",
        "\n",
        "# for i in range(len(pos_indices)):\n",
        "#     if pos_indices[i] == neg_indices_sample[i]:\n",
        "#         print(i)\n",
        "\n",
        "ls = [False]*10000\n",
        "\n",
        "# ls[pos_indices] = True\n",
        "\n",
        "ls_t = torch.tensor(ls, dtype = bool)\n",
        "# ls_t[pos_indices] = True\n",
        "ls_t[neg_indices_sample] = True\n",
        "ls_t.sum()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gcVPUeMMurI",
        "outputId": "b8678147-5abb-4405-8a89-ed35a2976ab7"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1367 1367\n",
            "[7048 7989 1804 ... 2116 6281 2491]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1367)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import Data\n",
        "\n",
        "# num_nodes, num_node_features\n",
        "x = torch.tensor(x, dtype=torch.float32)\n",
        "\n",
        "# num_nodes, 1\n",
        "y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "# 2, num_edges\n",
        "edge_index = torch.tensor(adj_ls, dtype=torch.long)\n",
        "\n",
        "# num_edges, num_edge_features\n",
        "edge_attr = torch.tensor(edges, dtype=torch.float32)\n",
        "\n",
        "# train-test split\n",
        "train_ls = [False]*num_train + [False]*num_test\n",
        "train_mask = torch.tensor(train_ls, dtype=bool)\n",
        "train_mask[pos_indices] = True\n",
        "train_mask[neg_indices_sample] = True\n",
        "test_ls = [False]*num_train + [True]*num_test\n",
        "test_mask = torch.tensor(test_ls, dtype=bool)\n",
        "\n",
        "\n",
        "data = Data(x=x, y=y, edge_index = edge_index.t().contiguous(), edge_attr=edge_attr, train_mask = train_mask, test_mask=test_mask)\n",
        "data = data.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXfkKRT6CGHV",
        "outputId": "d9c9adc1-25fc-4eda-f729-b26e4ef27fb7"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Number of nodes: {data.num_nodes}') # 节点数量\n",
        "print(f'Number of edges: {data.num_edges}') # 边数量\n",
        "print(f'Number of node features: {data.num_node_features}') # 节点属性的维度\n",
        "print(f'Number of node features: {data.num_features}') # 同样是节点属性的维度\n",
        "print(f'Number of edge features: {data.num_edge_features}') # 边属性的维度\n",
        "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}') # 平均节点度\n",
        "print(f'if edge indices are ordered and do not contain duplicate entries.: {data.is_coalesced()}') # 是否边是有序的同时不含有重复的边\n",
        "print(f'Number of training nodes: {data.train_mask.sum()}') # 用作训练集的节点\n",
        "print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}') # 用作训练集的节点的数量\n",
        "print(f'Contains isolated nodes: {data.has_isolated_nodes()}') # 此图是否包含孤立的节点\n",
        "print(f'Contains self-loops: {data.has_self_loops()}')  # 此图是否包含自环的边\n",
        "print(f'Is undirected: {data.is_undirected()}')  # 此图是否是无向图"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfxaz5LtCGFC",
        "outputId": "0137c0c8-206b-4f2a-f23d-3cbb0257d03f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of nodes: 10000\n",
            "Number of edges: 5561\n",
            "Number of node features: 10\n",
            "Number of node features: 10\n",
            "Number of edge features: 1\n",
            "Average node degree: 0.56\n",
            "if edge indices are ordered and do not contain duplicate entries.: False\n",
            "Number of training nodes: 2734\n",
            "Training node label rate: 0.27\n",
            "Contains isolated nodes: True\n",
            "Contains self-loops: False\n",
            "Is undirected: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = len(dataset[0][0])\n",
        "\n",
        "model = GNN(input_size, hidden_size, output_size).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "model.train()\n",
        "for epoch in range(200):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data)\n",
        "    loss = loss_fn(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "cCx5_Hl5CGCZ"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "pred = model(data).argmax(dim=1)\n",
        "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
        "acc = int(correct) / int(data.test_mask.sum())\n",
        "print(f'Accuracy: {acc:.4f}')\n",
        "Pred = pred[data.test_mask].cpu()\n",
        "Y = data.y[data.test_mask].cpu()\n",
        "C_Mat = metrics.confusion_matrix(Y, Pred)\n",
        "accuracy = metrics.accuracy_score(Y,Pred)\n",
        "f1 = metrics.f1_score(Y, Pred)\n",
        "recall = metrics.recall_score(Y, Pred)\n",
        "precision = metrics.precision_score(Y, Pred)\n",
        "print(C_Mat)\n",
        "print(f\"acc:{accuracy:.4f}, f1:{f1:.4f}, recall:{recall:.4f}, prec:{precision:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D44a9N5TCF6D",
        "outputId": "888090ca-ba47-41ff-8e0c-a55c5133d061"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6315\n",
            "[[1052  507]\n",
            " [ 230  211]]\n",
            "acc:0.6315, f1:0.3641, recall:0.4785, prec:0.2939\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save&Load Model"
      ],
      "metadata": {
        "id": "VNIQr9XuakxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 保存模型权重至当前文件夹\n",
        "torch.save(model.state_dict(), 'model_weights.pth')                             "
      ],
      "metadata": {
        "id": "tTO_IOiiarkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleNet(input_size, hidden_size, output_size)                         # 需要是同一个模型\n",
        "model.load_state_dict(torch.load('model_weights.pth'))\n",
        "model.eval()\n",
        "\n",
        "'''\n",
        "be sure to call model.eval() method before inferencing to set the dropout and batch normalization layers to evaluation mode. \n",
        "Failing to do this will yield inconsistent inference results.\n",
        "'''"
      ],
      "metadata": {
        "id": "nQejY8J8ay0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 直接保存/加载整个模型\n",
        "torch.save(model, 'model.pth')"
      ],
      "metadata": {
        "id": "u0CxBdcFdJkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('model.pth')"
      ],
      "metadata": {
        "id": "7HujEzt6d9k-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PISkr-lNd_iH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discoveries"
      ],
      "metadata": {
        "id": "6GSfZNi978Mu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "事实证明，只用ttl几乎相当于没有给模型提供有用信息，模型倾向于只预测其中一类。"
      ],
      "metadata": {
        "id": "wWQWhD2z8Bfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mKJ3OC1k7-al"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}